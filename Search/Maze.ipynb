{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search: Solving a Maze Using a Goal-based Agent\n",
    "\n",
    "Student Name: [Add your name]\n",
    "\n",
    "I have used the following AI tools: [list tools]\n",
    "\n",
    "I understand that my submission needs to be my own work: [your initials]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Outcomes\n",
    "\n",
    "* Formulate search problems using key components like initial state, actions, and goal state in a deterministic, fully observable environment.\n",
    "* Implement and compare search algorithms including BFS, DFS, GBFS, A*, and IDS for planning paths through mazes.\n",
    "* Analyze algorithm performance by measuring path cost, node expansions, depth, and memory usage across various maze types.\n",
    "* Use visualization tools to represent maze paths and support debugging and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Total Points: Undergrads 100 + 5 bonus / Graduate students 110\n",
    "\n",
    "Complete this notebook. Use the provided notebook cells and insert additional code and markdown cells as needed. Submit the notebook file and the completely rendered notebook with all outputs as a HTML file. \n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this exercise, we will implement the planning function for a type of goal-based agent called a __planning agent__. The planning function uses a map it is given to plan a path through the maze from the starting location $S$ to the goal location $G$. We will only focus on the planning function, so you do not need to implement an environment, just use the map to search for a path to solve the maze. \n",
    "\n",
    "Once the plan is made, the agent in a deterministic environment (i.e., the transition function is deterministic with the outcome of each state/action pair fixed and no randomness) can just follow the plan step-by-step and does not need to care about the percepts.\n",
    "This is also called an **[open-loop system](https://en.wikipedia.org/wiki/Open-loop_controller).**\n",
    "The execution phase is trivial and can be executed using a model-based reflex agent \n",
    "that ignores all percepts and just follows the plan. I will show you a short example, but you do not implement it in this exercise.\n",
    "\n",
    "Given that the agent has a complete and correct map, the environment is **fully observable, discrete, deterministic, and known.** \n",
    "Remember:\n",
    "\n",
    "* **Fully observable** means that the agent can see its state and what the available actions are. That means the **percepts contain the complete current state.**\n",
    "Here, during planning, the agent always sees its x and y coordinates on the map and\n",
    "also seeks when it has reached the goal state. \n",
    "* **Discrete** means that we have a **finite set of states.** The maze has a finite set \n",
    "of squares the agent can be in.\n",
    "* **Deterministic** means that the **transition function contains no randomness.** An action in a state will always produce the same result. Going south from the start state always will lead to the same square.\n",
    "* **Know** means that the agent **knows the complete transition function.** The \n",
    "agent has the map and therefore knows how its position changes when it walks in a direction.\n",
    "\n",
    "Tree search algorithm implementations that you find online typically come from data structures courses and have a different aim than AI tree search. These algorithms assume that you already have a tree in memory. We are interested in dynamically creating a search tree with the aim of finding a good/the best path from the root note to the goal state. Follow the pseudo code presented in the text book (and replicated in the slides) closely. Ideally, we would like to search only a small part of the maze, i.e., create a search tree with as few nodes as possible. \n",
    "\n",
    "Several mazes for this exercise are stored as text files. Here is the small example maze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXXXXXXXXXXXXXXXXX\n",
      "X XX        X X      X\n",
      "X    XXXXXX X XXXXXX X\n",
      "XXXXXX     S  X      X\n",
      "X    X XXXXXX XX XXXXX\n",
      "X XXXX X         X   X\n",
      "X        XXX XXX   X X\n",
      "XXXXXXXXXX    XXXXXX X\n",
      "XG         XX        X\n",
      "XXXXXXXXXXXXXXXXXXXXXX\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"small_maze.txt\", \"r\") as f:\n",
    "    maze_str = f.read()\n",
    "print(maze_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If you get an error here that the file cannot be found, then you need to download it. See [HOWTO Work on Assignments.](https://github.com/mhahsler/CS7320-AI/blob/master/HOWTOs/working_on_assignments.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing and pretty printing the maze\n",
    "\n",
    "The maze can also be displayed in color using code in the module [maze_helper.py](maze_helper.py). The code parses the string representing the maze and converts it into a `numpy` 2d array which you can use in your implementation. Position are represented as a 2-tuple of the form `(row, col)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position(0,0): X\n",
      "Position(8,1): G\n"
     ]
    }
   ],
   "source": [
    "import maze_helper as mh\n",
    "\n",
    "maze = mh.parse_maze(maze_str)\n",
    "\n",
    "# look at a position in the maze by subsetting the 2d array\n",
    "print(\"Position(0,0):\", maze[0, 0])\n",
    "\n",
    "# there is also a helper function called `look(maze, pos)` available\n",
    "# which uses a 2-tuple for the position.\n",
    "print(\"Position(8,1):\", mh.look(maze, (8, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A helper function to visualize the maze is also available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 269,
       "width": 534
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "# use higher resolution images in notebooks\n",
    "\n",
    "mh.show_maze(maze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the `(x,y)` position of the start and the goal using the helper function `find_pos()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start location: (np.int64(3), np.int64(11))\n",
      "Goal location: (np.int64(8), np.int64(1))\n"
     ]
    }
   ],
   "source": [
    "print(\"Start location:\", mh.find_pos(maze, what = \"S\"))\n",
    "print(\"Goal location:\", mh.find_pos(maze, what = \"G\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module maze_helper:\n",
      "\n",
      "NAME\n",
      "    maze_helper\n",
      "\n",
      "DESCRIPTION\n",
      "    Code for the Maze Assignment by Michael Hahsler\n",
      "    Usage:\n",
      "        import maze_helper as mh\n",
      "        mh.show_some_mazes()\n",
      "\n",
      "FUNCTIONS\n",
      "    animate_maze(result, repeat=False)\n",
      "        Build an animation from a list of mazes. Assumes that results has the elements:\n",
      "        path, reached, actions and maze_anim with a list of maze arrays.\n",
      "\n",
      "    find_pos(maze, what='S')\n",
      "        Find start/goal in a maze and returns the first one.\n",
      "        Caution: there is no error checking!\n",
      "\n",
      "        Parameters:\n",
      "        maze: a array with characters prodced by parse_maze()\n",
      "        what: the letter to be found ('S' for start and 'G' for goal)\n",
      "\n",
      "        Returns:\n",
      "        a tupple (x, y) for the found position.\n",
      "\n",
      "    look(maze, pos)\n",
      "        Look at the label of a square with the position as an array of the form (x, y).\n",
      "\n",
      "    maze_to_matrix(maze)\n",
      "        convert a maze a numeric numpy array for visualization via imshow.\n",
      "\n",
      "    parse_maze(maze_str)\n",
      "        Convert a maze as a string into a 2d numpy array\n",
      "\n",
      "    show_maze(maze, fontsize=10)\n",
      "        Display a (parsed) maze as an image.\n",
      "\n",
      "    welcome()\n",
      "        Welcome message.\n",
      "\n",
      "FILE\n",
      "    /home/mhahsler/github/CS7320-AI/Search/maze_helper.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(mh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to make a local copy of the module file [maze_helper.py](maze_helper.py) in the same folder where your notebook is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Example for a Planning Agent\n",
    "\n",
    "I will show you here how to implement a simple agent that uses a random plan. It will not solve the maze, but show you how the mechanics work.\n",
    "\n",
    "First, we define a generic planning agent that fist plans, and then executes the plan step-by-step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Planning_Agent:\n",
    "    def __init__(self, maze, start, goal, planning_function):\n",
    "        self.maze = maze\n",
    "        self.start = start\n",
    "        self.goal = goal\n",
    "        self.planning_function = planning_function\n",
    "        self.plan = None\n",
    "        self.progress = None\n",
    "\n",
    "    def act(self):\n",
    "        # plan if no plan exists\n",
    "        if self.plan is None:\n",
    "            print(\"Planning...\")\n",
    "            self.plan = self.planning_function(self.maze, self.start, self.goal)\n",
    "            self.progress = 0\n",
    "        \n",
    "        # check if plan is completed\n",
    "        if self.progress >= len(self.plan):        \n",
    "            raise Exception(\"Completed Plan. No more planned actions\")\n",
    "        \n",
    "        # follow the plan\n",
    "        action = self.plan[self.progress]\n",
    "        print(f\"Following plan... step {self.progress}: {action}\")\n",
    "\n",
    "        self.progress += 1\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the planning function. This function is what you will implement in this assignment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['W', 'E', 'E', 'W', 'E', 'S', 'E', 'N', 'S', 'S']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def plan_random(maze, start, goal):\n",
    "    \"\"\"Create a random plan with 10 steps\"\"\"\n",
    "    plan = np.random.choice([\"N\", \"E\", \"S\", \"W\"], size=10, replace=True).tolist()\n",
    "    return plan\n",
    "\n",
    "plan_random(maze, (1,1), (8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This planning function is not great and will not produce a plan that solves the maze. Your planning functions will do better.\n",
    "\n",
    "Finally, we can create the planning agent, give it the planning function and implement a simple environment that asks it 11 times for an action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning...\n",
      "Following plan... step 0: W\n",
      "Following plan... step 1: S\n",
      "Following plan... step 2: S\n",
      "Following plan... step 3: N\n",
      "Following plan... step 4: W\n",
      "Following plan... step 5: W\n",
      "Following plan... step 6: W\n",
      "Following plan... step 7: W\n",
      "Following plan... step 8: E\n",
      "Following plan... step 9: W\n",
      "Agent exception: Completed Plan. No more planned actions\n"
     ]
    }
   ],
   "source": [
    "my_agent = Planning_Agent(maze, mh.find_pos(maze, what = \"S\"), mh.find_pos(maze, what = \"G\"), plan_random)\n",
    "\n",
    "def environment(agent_function, steps):\n",
    "    for _ in range(steps):\n",
    "        try:\n",
    "            agent_function()\n",
    "        except Exception as e:\n",
    "            print(f\"Agent exception: {e}\")\n",
    "\n",
    "environment(my_agent.act, steps=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The agent and environment implementation above is just an illustration. You will only implement and experiment with different versions of the planning function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree structure\n",
    "\n",
    "To use tree search, you will need to implement a tree data structure in Python. \n",
    "Here is an implementation of the basic node structure for the search algorithms (see Fig 3.7 on page 73). I have added a method that extracts the path from the root node to the current node. It can be used to get the path when the search is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, pos, parent, action, cost):\n",
    "        self.pos = tuple(pos)    # the state; positions are (row,col)\n",
    "        self.parent = parent     # reference to parent node. None means root node.\n",
    "        self.action = action     # action used in the transition function (root node has None)\n",
    "        self.cost = cost         # for uniform cost this is the depth. It is also g(n) for A* search\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Node - pos = {self.pos}; action = {self.action}; cost = {self.cost}\"\n",
    "    \n",
    "    def get_path_from_root(self):\n",
    "        \"\"\"returns nodes on the path from the root to the current node.\"\"\"\n",
    "        node = self\n",
    "        path = [node]\n",
    "    \n",
    "        while not node.parent is None:\n",
    "            node = node.parent\n",
    "            path.append(node)\n",
    "        \n",
    "        path.reverse()\n",
    "        \n",
    "        return(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If needed, then you can add more fields to the class like the heuristic value $h(n)$ or $f(n)$.\n",
    "\n",
    "Examples for how to create and use a tree and information on memory management can be found [here](../HOWTOs/trees.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "\n",
    "The goal is to:\n",
    "\n",
    "1. Implement the following search algorithms for solving different mazes:\n",
    "\n",
    "    - Breadth-first search (BFS)\n",
    "    - Depth-first search (DFS)\n",
    "    - Greedy best-first search (GBFS)\n",
    "    - A* search\n",
    "\n",
    "2. Run each of the above algorithms on the \n",
    "    - [small maze](small_maze.txt), \n",
    "    - [medium maze](medium_maze.txt), \n",
    "    - [large maze](large_maze.txt), \n",
    "    - [open maze](open_maze.txt),\n",
    "    - [wall maze](wall_maze.txt),\n",
    "    - [loops maze](loops_maze.txt),\n",
    "    - [empty maze](empty_maze.txt), and\n",
    "    - [empty 2_maze](empty_2_maze.txt).\n",
    "    \n",
    "3. For each problem instance and each search algorithm, report the following in a table:\n",
    "\n",
    "    - The solution and its path cost\n",
    "    - Total number of nodes expanded\n",
    "    - Maximum tree depth\n",
    "    - Maximum size of the frontier\n",
    "\n",
    "4. Display each solution by marking every maze square (or state) visited and the squares on the final path.\n",
    "\n",
    "## General [10 Points]\n",
    "\n",
    "1. Make sure that you use the latest version of this notebook.\n",
    "2. Your implementation can use libraries like math, numpy, scipy, but not libraries that implement intelligent agents or complete search algorithms. Try to keep the code simple! In this course, we want to learn about the algorithms and we often do not need to use object-oriented design.\n",
    "3. You notebook needs to be formatted professionally. \n",
    "    - Add additional markdown blocks for your description, comments in the code, add tables and use mathplotlib to produce charts where appropriate\n",
    "    - Do not show debugging output or include an excessive amount of output.\n",
    "    - Check that your submitted file is readable and contains all figures.\n",
    "4. Document your code. Use comments in the code and add a discussion of how your implementation works and your design choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Defining the search problem and determining the problem size [10 Points]\n",
    "\n",
    "Define the components of the search problem:\n",
    "\n",
    "* Initial state\n",
    "* Actions\n",
    "* Transition model\n",
    "* Goal state\n",
    "* Path cost\n",
    "\n",
    "Use verbal descriptions, variables and equations as appropriate. \n",
    "\n",
    "*Note:* You can swich the next block from code to Markdown and use formating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give some estimates for the problem size:\n",
    "\n",
    "* $n$: state space size\n",
    "* $d$: depth of the optimal solution\n",
    "* $m$: maximum depth of tree\n",
    "* $b$: maximum branching factor\n",
    "\n",
    "Describe how you would determin these values for a given maze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Uninformed search: Breadth-first and depth-first [40 Points]\n",
    "\n",
    "Implement these search strategies. Follow the pseudocode in the textbook/slides. You can use the tree structure shown above to extract the final path from your solution.\n",
    "\n",
    "Read the following **important notes** carefully:\n",
    "* You can find maze solving implementations online that use the map to store information. While this is an effective idea for this two-dimensional navigation problem, it typically cannot be used for other search problems. Therefore, follow the textbook and **do not store information in the map.** Only store information in the tree created during search, and use the `reached` and `frontier` data structures where appropriate.\n",
    "* DSF behavior can be implemented using the BFS tree search algorithm and simply changing the order in which the frontier is expanded (this is equivalent to best-first search with path length as the criterion to expand the next node). However, this would be a big mistake since it combines the bad space complexity of BFS with the bad time complexity of DFS! **To take advantage of the significantly smaller memory footprint of DFS, you need to implement DFS in a different way without a `reached` data structure (often also called `visited` or `explored`) and by releasing the memory for nodes that are not needed anymore.**\n",
    "* Since the proper implementation of DFS does not use a `reached` data structure, redundant path checking abilities are limited to cycle checking. \n",
    "You need to implement **cycle checking since DSF is incomplete (produces an infinite loop) if cycles cannot be prevented.** You will see in your experiments that cycle checking in open spaces is challenging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does BFS and DFS (without a reached data structure) deal with loops (cycles)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are your implementations complete and optimal? Explain why. What is the time and space complexity of each of **your** implementations? Especially discuss the difference in space complexity between BFS and DFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Informed search: Implement greedy best-first search and A* search  [20 Points]\n",
    "\n",
    "You can use the map to estimate the distance from your current position to the goal using the Manhattan distance (see https://en.wikipedia.org/wiki/Taxicab_geometry) as a heuristic function. Both algorithms are based on Best-First search which requires only a small change from the BFS algorithm you have already implemented (see textbook/slides). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are your implementations complete and optimal? What is the time and space complexity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Comparison and discussion [20 Points] \n",
    "\n",
    "Run experiments to compare the implemented algorithms.\n",
    "\n",
    "How to deal with issues:\n",
    "\n",
    "* Your implementation returns unexpected results: Try to debug and fix the code. Visualizing the maze, the current path and the frontier after every step is very helpful. If the code still does not work, then mark the result with an asterisk (*) and describe the issue below the table.\n",
    "\n",
    "* Your implementation cannot consistently solve a specific maze and ends up in an infinite loop:\n",
    "    Debug (likely your frontier and cycle checking for DFS are the issue). If it is a shortcoming of the algorithm/implementation, then put \"N/A*\" in the results table and describe why this is happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the following table for each maze.\n",
    "\n",
    "__Small maze__\n",
    "\n",
    "| algorithm | path cost | # of nodes expanded | max tree depth | max # of nodes in memory | max frontier size |\n",
    "|-----------|-----------|----------------|----------------|---------------|-------------------|\n",
    "| BFS       |           |                |                |               |                   |\n",
    "| DFS       |           |                |                |               |                   |\n",
    "| GBS       |           |                |                |               |                   |\n",
    "| A*        |           |                |                |               |                   |\n",
    "\n",
    "__Medium Maze__\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Present the results as using charts (see [Python Code Examples/charts and tables](../HOWTOs/charts_and_tables.ipynb)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss the most important lessons you have learned from implementing the different search strategies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced task: IDS and Multiple goals\n",
    "\n",
    "* __Graduate students__ need to complete this task [10 points]\n",
    "* __Undergraduate students__ can attempt this as a bonus task [max +5 bonus points].\n",
    "\n",
    "### IDS \n",
    "Implement IDS (iterative deepening search) using your DFS implementation. Test IDS on the mazes above. You may run into some issues with mazes with open spaces. If you cannot resolve the issues, then report and discuss what causes the problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/answer goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Goals \n",
    "Create a few mazes with multiple goals by adding one or two more goals to the medium size maze. The agent is done when it finds one of the goals.\n",
    "Solve the maze with your implementations for DFS, BFS, and IDS. Run experiments to show which implementations find the optimal solution and which do not. Discuss why that is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/answer goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Advanced Problems to Think About (not for credit)\n",
    "\n",
    "If the assignment was to easy for yuo then you can think about the following problems. These problems are challenging and not part of this assignment. \n",
    "\n",
    "### Intersection as States\n",
    "Instead of defining each square as a state, use only intersections as states. Now the storage requirement is reduced, but the path length between two intersections can be different. If we use total path length measured as the number of squares as path cost, how can we make sure that BFS and iterative deepening search is optimal? Change the code to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/answer goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted A* search\n",
    "Modify your A* search to add weights (see text book) and explore how different weights influence the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/answer goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unknown Maze\n",
    "What happens if the agent does not know the layout of the maze in advance? This means that the agent faces an unknown environment, where it does not know the transition function. How does the environment look then (PEAS description)? How would you implement a rational agent to solve the maze? What if the agent still has a GPS device to tell the distance to the goal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/answer goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
