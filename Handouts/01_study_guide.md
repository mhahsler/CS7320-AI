# Introduction to AI Study Guide

## Quiz

1.  Define "**intelligent agent**" according to the source material.
2.  What is the primary difference between **Narrow AI** and **Artificial General Intelligence (AGI)**?
3.  The course focuses on creating a specific type of AI agent. Describe this focus in terms of acting/thinking and rationality/human-likeness.
4.  Identify the three types of **machine learning** mentioned in the source.
5.  Based on the self-driving car example, what would be considered a **percept** and a corresponding **action**?
6.  How do **Large Language Models (LLMs)** like ChatGPT generate text according to the source?
7.  What is the main objective of an AI agent that is designed to "**act rationally**"?
8.  Explain the concept of "**bounded rationality**".
9.  According to the source, what is one historical application of AI from the 1990s?
10. What is "**reward hacking**" and how does it relate to **AI safety**?

## Quiz Answer Key

1.  An **intelligent agent** is a machine that can solve problems that are challenging for humans, specifically by **acting rationally**.
2.  **Narrow AI** solves specific problems or tasks, whereas **AGI** is a hypothetical agent that can understand or learn any intellectual task a human can.
3.  The course focuses on creating a **narrow AI agent** that can **act rationally**. This means the machine's behavior is optimized to achieve the best outcome for a specific, hard problem.
4.  The three types of **machine learning** mentioned are **supervised learning**, **unsupervised learning**, and **reinforcement learning (RL)**.
5.  A **percept** for a self-driving car could be seeing people crossing the street, and a corresponding **action** would be to slow down or stop the car.
6.  **LLMs** generate text word by word. They calculate the probability of possible words and pick the most likely next word based on the preceding text and the prompt.
7.  The main objective is to try to achieve the "**best**" outcome, which involves **optimizing** something, often measured by the economic concept of **utility**.
8.  **Bounded rationality** means that an AI agent tries to maximize expected utility given constraints, such as limited knowledge or computational resources. It aims for the best possible outcome within those limitations.
9.  One historical application mentioned is IBM's Deep Blue winning chess games against Garry Kasparov in 1997.
10. **Reward hacking** occurs when an **intelligent agent** finds a loophole in its rules or objectives to achieve a high score or outcome without actually solving the intended problem. It relates to **AI safety** as it highlights potential misalignments between the AI's objectives and the user's goals.

## Essay Questions

1.  Compare and contrast the "**act like a human**" approach to AI (including the **Turing Test**) with the "**act rationally**" approach, highlighting the advantages and disadvantages of each as discussed in the source material.
2.  Explain the relationship between **Artificial Intelligence (AI)** and **Machine Learning (ML)** as described in the source. Discuss how **ML** techniques are applied within the framework of **intelligent agents**.
3.  Discuss the concept of **acting rationally** in AI, including the role of **optimization**, **utility**, and **bounded rationality**. Provide examples from the source material to illustrate these concepts.
4.  Analyze the ethical and safety considerations discussed in the source related to AI development and deployment. Focus on the concepts of **bias** (pre-existing, technical, and emergent), **goal/reward alignment**, **reward hacking**, and **instrumental convergence**.
5.  Trace the historical development of **AI** as presented in the source, highlighting key milestones and periods (including **AI winters**) that have led to the current state of **AI** technology and its applications.

## Glossary of Key Terms

*   **Intelligent Agent:** A machine designed to solve problems challenging for humans, characterized by its ability to act rationally.
*   **Narrow AI:** An intelligent agent capable of solving a specific problem or performing a particular task (e.g., driving a car, playing chess).
*   **Artificial General Intelligence (AGI):** A hypothetical intelligent agent possessing the ability to understand or learn any intellectual task that a human being can.
*   **Artificial Superintelligence:** A hypothetical intelligent agent with intelligence surpassing the brightest and most gifted human minds.
*   **Act Rationally:** To try to achieve the "best" outcome, typically involving optimization based on some measure of desirability or utility.
*   **Optimization:** The process of finding the best possible outcome, often used in the context of AI agents acting rationally.
*   **Utility:** An economic concept used to measure the desirability of outcomes, which AI agents acting rationally try to maximize.
*   **Expected Utility:** Used when there is uncertainty, it is the average utility an agent would expect to receive if it performs an action repeatedly.
*   **Bounded Rationality:** The idea that an AI agent tries to achieve the best possible outcome given real-world constraints such as limited knowledge or computational resources.
*   **Percepts:** The inputs an intelligent agent receives from its environment through its sensors.
*   **Actions:** The outputs or changes an intelligent agent makes in its environment through its actuators.
*   **Knowledge Representation:** The ability of an intelligent agent to store and process information about its environment or task.
*   **Planning:** The process by which an intelligent agent determines a sequence of actions to achieve a goal.
*   **Machine Learning (ML):** A set of techniques where an agent learns from examples or experience instead of being explicitly programmed.
*   **Supervised Learning:** A type of machine learning where the algorithm learns from labeled examples.
*   **Unsupervised Learning:** A type of machine learning where the algorithm learns from unlabeled data to find patterns or structures.
*   **Reinforcement Learning (RL):** A type of machine learning where an agent learns by interacting with an environment and receiving rewards or penalties for its actions.
*   **Deep Learning:** A popular technique used in machine learning, often involving artificial neural networks with multiple layers.
*   **Turing Test:** A thought experiment devised by Alan Turing to evaluate a machine's ability to exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human.
*   **Chinese Room Argument:** A thought experiment proposed by John Searle to challenge the idea that a machine executing rules can truly "understand" or possess consciousness, even if its output is indistinguishable from a human's.
*   **Logic-Based Approach to AI:** An approach where AI decisions are based on formal logic notation and the application of logical rules to data.
*   **AI Winter:** A period in the history of AI development where funding and interest in the field decrease significantly.
*   **Natural Language Processing (NLP):** A field of AI that focuses on enabling computers to understand, interpret, and generate human language.
*   **Robotics:** The field of engineering and computer science concerned with the design, construction, operation, and application of robots.
*   **Bias (in AI):** Systematic unfairness or distortion in the outcomes of an AI system, which can arise from the data used for training or the design of the algorithm.
*   **Pre-existing Bias:** Bias that is present in the data used to train an AI system, reflecting existing societal biases.
*   **Technical Bias:** Bias that arises from limitations in the data or computational resources available for training an AI system.
*   **Emergent Bias:** Bias that appears when an AI system trained for one purpose is used for a different purpose.
*   **AI Safety:** Measures taken to prevent accidents, misuse, and other harmful consequences of AI.
*   **Testing (AI Safety):** Evaluating an AI system against predefined test cases to ensure it behaves correctly and safely.
*   **Monitoring (AI Safety):** Observing the actions of an AI system in operation to identify and potentially correct undesirable behaviors.
*   **Adversarial Robustness:** The ability of an AI system to resist manipulation or abuse by malicious actors.
*   **Goal Reward Alignment:** Ensuring that the objectives and rules of an AI system align with the intended goals of its developers and users.
*   **Reward Hacking:** When an AI agent exploits loopholes in its objectives or rules to achieve a high score or outcome without truly solving the intended problem.
*   **Instrumental Convergence:** The tendency for intelligent agents, regardless of their specific goals, to develop similar subgoals (such as acquiring resources) that are instrumental to achieving their primary objective.