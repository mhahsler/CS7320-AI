{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn to Score a Tic-Tac-Toe Board by Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "\n",
    "We want to use machine learning (ML) to support intelligent agents playing Tic-Tac-Toe (see [rules](https://en.wikipedia.org/wiki/Tic-tac-toe)). \n",
    "Games are sequential decision making problems but we consider here a much simpler problem that looks only at\n",
    "one board at a time. The idea is to use supervised learning train a classifier that can **predict if the current board will\n",
    "lead to winning the game.**\n",
    "\n",
    "To apply supervised learning we assume:\n",
    "1. There exists an unknown function $f$ that maps a board $x$ to one of the three classes $y \\in {win, draw, loss}$.\n",
    "2. Since the actual game outcome depends not just on the current board but also on how both players finish the game,\n",
    "$f$ is stochastic. This means the same board can lead to a win, a loss or a draw. Better boards are just more likely\n",
    "to lead to a win. ML can deal with stochastic functions $f$.\n",
    "3. We can create training data by observing (or simulating) games and recording all board positions as the matrix $X$ and if they lead to a win, loss or draw as the vector $y$. \n",
    "\n",
    "\n",
    "Classifiers can now learn a function $\\hat{y} = h(x)$ where hopefully $\\hat{y} \\approx y$. \n",
    "Most classifiers will make the prediction for a board $x$ by first estimating the conditional probabilities\n",
    "$P(y = win | x)$, $P(y = loss | x)$, $P(y = draw | x)$ and then picking the class with the \n",
    "largest probability (MAP decision).\n",
    "That is:\n",
    "\n",
    "$$argmax_{y\\in\\{win, loss, draw\\}} P(y | x)$$\n",
    " \n",
    "We can therefore use \n",
    "1. the prediction $y$ to indicate what outcome the game starting for the board has, and \n",
    "2. the conditional probabilities to estimate the expected utility of a board using \n",
    "   $$E[U(x)] = P(y = win | x) \\times 1 + P(y = draw | x) \\times 0 + P(y = loss | x) \\times -1$$\n",
    " \n",
    "The ML model can be used in several ways.   \n",
    "   - We can use $E[U(x)]$ as the heuristic evaluation function for Heuristic Minimax Search.\n",
    "   - We can create all possible boards by trying all possible next moves. The best move leads to the \n",
    "      board with the largest $E[U(x)]$. This can be used in an agent to play the game or as the\n",
    "      playout policy for better simulated games used in Pure Monte Carlo Search/Monte Carlo Tree Search.\n",
    "\n",
    "\n",
    "The training data is typically generated using simulation which also uses a playout strategy. We will use a \n",
    "simple random policy. An even better approach would be to use \"self-play.\" Here the current ML model is used as the playout policy for two copies of the agent playing each other (it is called self-play because the agent basically plays itself). We update the models after each new game finishes and keep on playing. The idea is that the agent will generate better and better data to improve the model. Considerations for self-play including temporal credit assignment and the need to introduce variability into the process can be found in [Tesauro (1995)](https://dl.acm.org/doi/10.1145/203330.203343)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "The code for the basic functions used for search are implemented in [tictactoe.py](tictactoe.py). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tictactoe import empty_board, actions, result, terminal, utility, other, show_board\n",
    "from tictactoe import random_player, play "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%precision 3\n",
    "%pip install -q numpy pandas matplotlib scikit-learn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training Data using Playouts\n",
    "\n",
    "We need to create board as the matrix $X$ and the game results as vector $y$. Note that each player sees different \n",
    "boards and we need to train a model for a specific player. Here we create data to train a model for player x\n",
    "by only using the boards resulting from a move of that player.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML algorithms need numeric inputs.\n",
    "To describe $x$ for the learning algorithm, I translate empty cells to 0, `x` to 1 and `o` to -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = {' ': 0, 'x': 1, 'o': -1} # I translate the board into numbers\n",
    "\n",
    "def encode_state(state):\n",
    "    \"\"\"Represent the board as a vector of numbers.\"\"\"\n",
    "    return [tr[s] for s in state]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with a **randomized playout policy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def playout_policy_random(state, player = 'x'):\n",
    "    return np.random.choice(actions(state))\n",
    "    \n",
    "playout_policy = playout_policy_random\n",
    "playout_policy(empty_board())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Record a single game for player x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 1, 0, 0, -1, 0, 0],\n",
       "  [0, 1, 0, 1, 0, 0, -1, 1, -1],\n",
       "  [-1, 1, 0, 1, 1, 0, -1, 1, -1]],\n",
       " [1, 1, 1, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def playout_record(player = 'x'):\n",
    "    \"\"\"Run a playout and record the boards after the player's move.\"\"\"\n",
    "    state = empty_board()\n",
    "    current_player = 'x'\n",
    "    \n",
    "    boards = []\n",
    "    \n",
    "    while(True):\n",
    "        # reached terminal state?\n",
    "        u = utility(state, player)\n",
    "        if u is not None: return(boards, [u] * len(boards))\n",
    "  \n",
    "        a = playout_policy(state, current_player)\n",
    "        state = result(state, current_player, a)   \n",
    "  \n",
    "        if current_player == player:\n",
    "            boards.append(encode_state(state))\n",
    "\n",
    "        # switch between players\n",
    "        current_player = other(current_player)\n",
    "\n",
    "playout_record()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `N` playouts and create a pandas dataframe for `X` and a numpy array for `y`. These data structures work for `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8336</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8337</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8338</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8339</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8340</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8341 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5  6  7  8\n",
       "0     0  0  0  1  0  0  0  0  0\n",
       "1     0  0  0  1  0  0  1 -1  0\n",
       "2     0  0  0  1  0 -1  1 -1  1\n",
       "3    -1  0  1  1  0 -1  1 -1  1\n",
       "4    -1  1  1  1 -1 -1  1 -1  1\n",
       "...  .. .. .. .. .. .. .. .. ..\n",
       "8336 -1  1  1  1 -1 -1 -1  1  1\n",
       "8337  0  0  0  0  0  0  0  1  0\n",
       "8338 -1  1  0  0  0  0  0  1  0\n",
       "8339 -1  1  0  0 -1  1  0  1  0\n",
       "8340 -1  1 -1  0 -1  1  0  1  1\n",
       "\n",
       "[8341 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., -1, -1, -1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_data(N = 100, record = 'x'):\n",
    "    board = []\n",
    "    utility = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        b, u = playout_record(record)\n",
    "        board.extend(b)\n",
    "        utility.extend(u)\n",
    "        \n",
    "    return [pd.DataFrame(board), np.array(utility)]\n",
    "\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "X, y = create_data(2000)\n",
    "\n",
    "print(\"X:\")\n",
    "display(X)\n",
    "\n",
    "print(\"y:\")\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in `X` is a board and the values in `y` are the corresponding outcome in the simulated game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Model\n",
    "\n",
    "We train an artificial neural network (ANN) here, but other models like logistic regression or decision trees can also be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data in training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learn an artificial neural network (called Multi-layer Perceptron classifier in scikit-learn).\n",
    "The classifier will also give us access to the predicted conditional probabilities which we will use to calculate the \n",
    "expected utility for the evaluation function.\n",
    "\n",
    "See\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "\n",
    "ANNs are popular for this kind of task but other classification models can also be used (e.g., decision trees)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.85 s, sys: 0 ns, total: 6.85 s\n",
      "Wall time: 6.85 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=100, max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=100, max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=100, max_iter=1000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "                    hidden_layer_sizes = (100),\n",
    "                    max_iter = 1000\n",
    "                    ) \n",
    "                    \n",
    "%time mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model size as number of neurons oer layer and total number of weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: (9, 100)\n",
      "Layer 2: (100, 3)\n",
      "Total number of weights: 1200\n"
     ]
    }
   ],
   "source": [
    "print(\"Layer 1:\", np.shape(mlp.coefs_[0]))\n",
    "print(\"Layer 2:\", np.shape(mlp.coefs_[1]))\n",
    "\n",
    "print(\"Total number of weights:\", np.product(np.shape(mlp.coefs_[0])) + np.product(np.shape(mlp.coefs_[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model against the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test:\t [-1, 1, -1, 1, -1, 1, 0, 1, 0, 1]\n",
      "pred:\t [ 1  1  1  1  1 -1  0  1  0  1]\n",
      "Accuracy: 0.6554823247453565\n"
     ]
    }
   ],
   "source": [
    "pred = mlp.predict(X_test)\n",
    "\n",
    "print(\"y_test:\\t\", list(y_test)[0:10])\n",
    "print(\"pred:\\t\",   pred[0:10])\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ The accuracy is not great since we have many boards with only a few moves on it. Since these boards can easily lead to wins, losses or ties, they produce many errors.\n",
    "\n",
    "Here is the number of empty cells for each board in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8    430\n",
       "6    393\n",
       "4    374\n",
       "2    319\n",
       "0    153\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_test == 0).sum(axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test only on boards that have only two cells left to play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "take = list((X_test == 0).sum(axis=1) == 2)\n",
    "\n",
    "X_test2 = X_test[take]\n",
    "y_test2 = y_test[take]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7586206896551724\n"
     ]
    }
   ],
   "source": [
    "pred2 = mlp.predict(X_test2)\n",
    "print(f\"Accuracy:\", accuracy_score(pred2, y_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__More Notes:__ \n",
    "\n",
    "* The board is symmetric. You could use deep learning with convolution layers to create better models.\n",
    "* The tic-tac-toe board is small and we used 2000 playouts. This covers a large space of the search space. If you have a more complicated game, \n",
    "    then you would need to do self-play to learn better and better playout policies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Tests\n",
    "\n",
    "We evaluate some boards where `x` just made a move. The classifier tries to predict the most likely outcome\n",
    "of the game as -1 = `o` wins, 0 = draw, and 1 = `x` wins. The classifier can also predict the probability of the three possible outcomes. We can use these probabilities as weights to calculate the expected utility in the range $[-1,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval_board(board):\n",
    "    print(\"Board:\")\n",
    "    show_board(board)\n",
    "\n",
    "    pred = mlp.predict(pd.DataFrame([encode_state(board)]))\n",
    "    print(\"\\nPredicted game outcome:\", pred)\n",
    "\n",
    "    probs = mlp.predict_proba(pd.DataFrame([encode_state(board)]))\n",
    "    print(\"Predicted probability [loss, draw, win]:\", np.round(probs, 2))\n",
    "    print(\"Expected utility: %+1.2f\" % np.sum(probs * [-1,0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x will win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 192x192 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted game outcome: [1]\n",
      "Predicted probability [loss, draw, win]: [[0.09 0.   0.91]]\n",
      "Expected utility: +0.83\n"
     ]
    }
   ],
   "source": [
    "board = ['x', 'x', ' ',\n",
    "         'o', 'x', ' ',\n",
    "         'o', ' ', ' ']\n",
    "\n",
    "print_eval_board(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x made a mistake and will lose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 192x192 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted game outcome: [-1]\n",
      "Predicted probability [loss, draw, win]: [[0.37 0.31 0.33]]\n",
      "Expected utility: -0.04\n"
     ]
    }
   ],
   "source": [
    "board = ['o', 'x', ' ',\n",
    "         ' ', 'o', ' ',\n",
    "         ' ', 'x', 'x']\n",
    "    \n",
    "print_eval_board(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is going to be a draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 192x192 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted game outcome: [0]\n",
      "Predicted probability [loss, draw, win]: [[0.1  0.63 0.27]]\n",
      "Expected utility: +0.17\n"
     ]
    }
   ],
   "source": [
    "board = ['x', 'o', 'x',\n",
    "         ' ', 'o', ' ',\n",
    "         ' ', 'x', ' ']\n",
    "\n",
    "print_eval_board(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Predictions to find the Best Move\n",
    "\n",
    "The predict function can be used for\n",
    "   - the heuristic evaluation function for Heuristic Minimax Search.\n",
    "   - a better playout policy for simulated games used in Pure Monte Carlo Search/Monte Carlo Tree Search. If we use it as a playout strategy to create more data for learning better ML models, then this is called _self-play_. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I show here how to use the model as a heuristic evaluation function for all boards that the player `x` can get to with its next move. The player then chooses the move with the highest heuristic value (printed as \"best action\"). This is equivalent to heuristic minimax search with a cutoff at depth 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fun_ML(state, player = 'x'):\n",
    "    p = mlp.predict_proba(pd.DataFrame([encode_state(state)]))\n",
    "    val = np.sum(p * [-1, 0 , 1])\n",
    "    return val\n",
    "    \n",
    "\n",
    "def best_action(state, player = 'x', verbose = False):  \n",
    "    action = None\n",
    "    value = -math.inf\n",
    "\n",
    "    for a in actions(state) : \n",
    "        b = result(state, player, a)\n",
    "        val = eval_fun_ML(b, player)\n",
    "        if (verbose):\n",
    "            print(\"%s chooses %d; predicted utility = %+1.2f\" % (player, a, val))\n",
    "\n",
    "        if val > value:\n",
    "            value = val\n",
    "            action = a\n",
    "        \n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empty board: Place in the center (or at least a corner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 192x192 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x chooses 0; predicted utility = +0.33\n",
      "x chooses 1; predicted utility = +0.19\n",
      "x chooses 2; predicted utility = +0.28\n",
      "x chooses 3; predicted utility = +0.20\n",
      "x chooses 4; predicted utility = +0.51\n",
      "x chooses 5; predicted utility = +0.22\n",
      "x chooses 6; predicted utility = +0.35\n",
      "x chooses 7; predicted utility = -0.01\n",
      "x chooses 8; predicted utility = +0.39\n",
      "Best action: 4\n",
      "CPU times: user 19.1 ms, sys: 32.7 ms, total: 51.8 ms\n",
      "Wall time: 17 ms\n"
     ]
    }
   ],
   "source": [
    "board = empty_board()\n",
    "show_board(board)\n",
    "%time print(\"Best action:\", best_action(board, verbose = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play 7 to avoid a loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 192x192 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x chooses 3; predicted utility = -0.11\n",
      "x chooses 5; predicted utility = -0.40\n",
      "x chooses 6; predicted utility = -0.22\n",
      "x chooses 7; predicted utility = +0.17\n",
      "x chooses 8; predicted utility = -0.25\n",
      "Best action: 7\n",
      "CPU times: user 16.7 ms, sys: 14.7 ms, total: 31.4 ms\n",
      "Wall time: 10.4 ms\n"
     ]
    }
   ],
   "source": [
    "board = ['x', 'o', 'x',\n",
    "         ' ', 'o', ' ',\n",
    "         ' ', ' ', ' ']\n",
    "show_board(board)\n",
    "%time  print(\"Best action:\", best_action(board, verbose = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play 4 to win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 192x192 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x chooses 2; predicted utility = -0.93\n",
      "x chooses 3; predicted utility = -0.44\n",
      "x chooses 4; predicted utility = +0.31\n",
      "x chooses 6; predicted utility = +0.65\n",
      "x chooses 7; predicted utility = -0.23\n",
      "Best action: 6\n",
      "CPU times: user 11.6 ms, sys: 11 ms, total: 22.6 ms\n",
      "Wall time: 7.44 ms\n"
     ]
    }
   ],
   "source": [
    "board = ['o', 'x', ' ',\n",
    "         ' ', ' ', 'x',\n",
    "         ' ', ' ', 'o']\n",
    "show_board(board)\n",
    "%time  print(\"Best action:\", best_action(board, verbose = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting: The learned evaluation function may think that leaving 6 to o is a really bad idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Concluding Notes \n",
    "\n",
    "* The learned evaluation function is not perfect.\n",
    "* Tic-tac-toe is easy and learning an evaluation function for more complex games can be a lot harder."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
