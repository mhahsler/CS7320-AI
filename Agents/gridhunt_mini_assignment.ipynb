{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligent Agents: Reflex-Based Agents for GridHunt\n",
    "\n",
    "Student Name: [Add your name]\n",
    "\n",
    "I have used the following AI tools: [list tools]\n",
    "\n",
    "I understand that my submission needs to be my own work: [your initials]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Outcomes\n",
    "\n",
    "* Apply core AI concepts by implementing the agent function for a simple and model-based reflex agents that respond to environmental percepts.\n",
    "* Practice how the environment and the agent function interact.\n",
    "* Analyze agent performance through controlled experiments across different environment configurations.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Total Points: Undergrads 10\n",
    "\n",
    "Complete this notebook. Use the provided notebook cells and insert additional code and markdown cells as needed. Submit the completely rendered notebook.\n",
    "### AI Use\n",
    "\n",
    "Here are some guidelines that will make it easier for you:\n",
    "\n",
    "* __Don't:__ Rely on AI auto completion. You will waste a lot of time trying to figure out how the suggested code relates to what we do in class. Turn off AI code completion (e.g., Copilot) in your IDE.\n",
    "* __Don't:__ Do not submit code/text that you do not understand or have not checked to make sure that it is complete and correct.\n",
    "* __Do:__ Use AI for debugging and letting it explain code and concepts from class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "![GridHunt Image](https://mhahsler.github.io/CS7320-AI/Agents/gridhunt.png)\n",
    "\n",
    "Gridhunt-Agent is a small educational game to play with implementing simple agent functions. It is a modified Python reimplementation based on [Gridhunt2](https://michael.hahsler.net/SMU/CS1342/gridhunt2/). \n",
    "\n",
    "The objective of gridhunt is to implement a hunter who can catch the monster faster than all other hunters. Gridhunt uses a $n \\times n$ grid of squares and a monster moves on this grid. Gridhunt is turn-based. A hunter catches the monster if she/he moves on the same square the monster currently occupies first. If the monster survives `max_step` rounds, the monster wins.\n",
    "\n",
    "## PEAS description of the cleaning phase\n",
    "\n",
    "__Performance Measure:__ Each action costs 1 energy unit (i.e., a step). The performance is measured as the sum of the energy units (steps) used to catch the monster. Catching the monster means to be on the same square.\n",
    "\n",
    "__Environment:__ An arena with $n \\times n$ squares. At the beginning the monster and the player is randomly placed in the arena environment.\n",
    "\n",
    "__Actuators:__ The agent can move to an adjacent square or teleport which will move the agent to a random square in the arena.\n",
    "\n",
    "__Sensors:__ The agent can see its location in the arena and the location of the monster.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Arena Environment\n",
    "\n",
    "The environment manages the location of the agents (hunter and monster). It initially places them in a random location and then provides them in every step with percepts and asks them for their action. \n",
    "\n",
    "__A Note on positions:__\n",
    "The arena is an array with row and column indices representing the position.\n",
    "Positions are stored in a numpy array where `pos[0]` is the row index and `pos[1]` is the column index in the arena. Remember indices in Python start with 0 and go to `n-1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "\n",
    "def arena_environment(hunter_agent_function, monster_agent_function, n = 30, max_steps = 100, visualize = False, animation = False):\n",
    "    \"\"\"\n",
    "    Simulate an arena where a hunter agent tries to catch a monster agent.\n",
    "\n",
    "    Parameters:\n",
    "    hunter_agent_function (function): A function that takes the current positions of the hunter and monster\n",
    "                                      and returns the next move for the hunter ('north', 'east', 'west', 'south', 'teleport').\n",
    "    monster_agent_function (function): A function that takes the current positions of the hunter and monster\n",
    "                                       and returns the next move for the monster (or 'stay' to remain in place).\n",
    "    n (int): The size of the arena (n x n grid).\n",
    "    max_steps (int): The maximum number of steps to simulate.\n",
    "    visualize (bool): Whether to visualize the arena.\n",
    "    animation (bool): Whether to animate the visualization with a delay.\n",
    "\n",
    "    Returns:\n",
    "    int: The number of steps taken for the hunter to catch the monster or np.nan (not a number) if not caught.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize positions\n",
    "    monster_pos = np.random.randint(0, n-1, size=2)\n",
    "    hunter_pos = np.random.randint(0, n-1, size=2)\n",
    "    \n",
    "    def move(action, position):\n",
    "        \"\"\"calculate new position for the agent.\"\"\"\n",
    "        if action == 'north':\n",
    "            position[0] -= 1\n",
    "        elif action == 'south':\n",
    "            position[0] += 1\n",
    "        elif action == 'west':\n",
    "            position[1] -= 1\n",
    "        elif action == 'east':\n",
    "            position[1] += 1\n",
    "        else:\n",
    "            raise ValueError(\"Invalid action.\")\n",
    "        \n",
    "        # Ensure position stays within bounds\n",
    "        position = np.clip(position, 0, n-1)\n",
    "        return position\n",
    "\n",
    "    def print_arena():\n",
    "\n",
    "        if animation:\n",
    "            sleep(1)\n",
    "            clear_output(wait=True)\n",
    "        print(f\"Step {step}:\")\n",
    "        print(f\"Hunter is at '{hunter_pos}'; Monster is at '{monster_pos}'\\n\")\n",
    "        arena = np.full((n, n), '.', dtype=str)\n",
    "        arena[monster_pos[0], monster_pos[1]] = 'M'\n",
    "        arena[hunter_pos[0], hunter_pos[1]] = 'H'\n",
    "        print(\"\\n\".join(\"\".join(row) for row in arena))\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        if visualize:\n",
    "            print_arena()\n",
    "        \n",
    "        # Check if hunter has caught the monster\n",
    "        if np.array_equal(hunter_pos, monster_pos):\n",
    "            if visualize:\n",
    "                print(f\"Hunter caught the monster in {step} steps!\")\n",
    "            return step\n",
    "        \n",
    "        # Get next move from monster agent function\n",
    "        monster_action = monster_agent_function(hunter_pos, monster_pos)\n",
    "        if monster_action != 'stay':\n",
    "            monster_pos = move(monster_action, monster_pos)\n",
    "\n",
    "        # Get next move from hunter agent function\n",
    "        hunter_action = hunter_agent_function(hunter_pos, monster_pos)\n",
    "        if hunter_action == 'teleport':\n",
    "            hunter_pos = np.random.randint(0, n-1, size=2)\n",
    "        else:\n",
    "            hunter_pos = move(hunter_action, hunter_pos)\n",
    "    \n",
    "        # print the agents' actions\n",
    "        if visualize:\n",
    "            print(f\"Hunter chose action '{hunter_action}'\")\n",
    "            print(f\"Monster chose action '{monster_action}'\")\n",
    "            print(\"\\n\" + \"=\"*n + \"\\n\")\n",
    "\n",
    "    # the hunter failed to catch the monster within max_steps\n",
    "    if visualize:\n",
    "        print(f\"Hunter failed to catch the monster in {max_steps} steps.\")\n",
    "    \n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I implement the monster here as a simple agent that moves around randomly, but mostly stays in its place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "monster_actions = [\"north\", \"east\", \"west\", \"south\", \"stay\"]\n",
    "\n",
    "def monster_agent_function_simple(hunter_pos, monster_pos):\n",
    "    return np.random.choice(monster_actions, p=[0.125, 0.125, 0.125, 0.125, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Hunter Agent\n",
    "\n",
    "Your job is to implement a simple-reflex hunter agent that can catch the monster. Remember, your agent is implemented as an agent function that get percepts and needs to return a valid action. The actions are: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [\"north\", \"east\", \"west\", \"south\", \"teleport\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simple Implementation\n",
    "\n",
    "Here is a very simple hunter that just runs around randomly and hopes that it bumps into the Monster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_randomized_hunter_agent_function(hunter_location, monster_location):\n",
    "    return np.random.choice(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting With the Agent\n",
    "\n",
    "We can place the monster and the hunter into the environment and run a simulation by calling the environment function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0:\n",
      "Hunter is at '[0 2]'; Monster is at '[1 3]'\n",
      "\n",
      "..H..\n",
      "...M.\n",
      ".....\n",
      ".....\n",
      ".....\n",
      "Hunter chose action 'east'\n",
      "Monster chose action 'stay'\n",
      "\n",
      "=====\n",
      "\n",
      "Step 1:\n",
      "Hunter is at '[0 3]'; Monster is at '[1 3]'\n",
      "\n",
      "...H.\n",
      "...M.\n",
      ".....\n",
      ".....\n",
      ".....\n",
      "Hunter chose action 'west'\n",
      "Monster chose action 'north'\n",
      "\n",
      "=====\n",
      "\n",
      "Step 2:\n",
      "Hunter is at '[0 2]'; Monster is at '[0 3]'\n",
      "\n",
      "..HM.\n",
      ".....\n",
      ".....\n",
      ".....\n",
      ".....\n",
      "Hunter chose action 'east'\n",
      "Monster chose action 'stay'\n",
      "\n",
      "=====\n",
      "\n",
      "Step 3:\n",
      "Hunter is at '[0 3]'; Monster is at '[0 3]'\n",
      "\n",
      "...H.\n",
      ".....\n",
      ".....\n",
      ".....\n",
      ".....\n",
      "Hunter caught the monster in 3 steps!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arena_environment(simple_randomized_hunter_agent_function, monster_agent_function_simple, n=5, max_steps=5, visualize=True, animation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, this was one run, maybe it was bad luck!\n",
    "\n",
    "Let's run an experiment with 100 runs in a $10 \\times 10$ arena.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 75, 7, nan, 41, nan, nan, 68, nan, 80, nan, nan, 59, 77, nan, 18, nan, 45, nan, nan, nan, 81, 60, 18, nan, nan, nan, 11, nan, 76, nan, nan, nan, nan, nan, 7, 2, 79, 41, nan, 59, nan, nan, 3, 0, nan, 13, nan, 1, 67, nan, 2, nan, nan, nan, nan, nan, nan, nan, 25, 14, 50, 99, 52, nan, 27, nan, 67, 63, 16, nan, 16, 80, 5, 73, nan, nan, 84, 55, nan, 91, 33, 39, 63, nan, nan, nan, 5, nan, 16, 28, 13, 41, 62, 13, nan, nan, 15, 57, 8]\n",
      "Hunter failed 45 times.\n",
      "Average steps to catch the monster over successful runs: 40.58\n"
     ]
    }
   ],
   "source": [
    "steps = [arena_environment(simple_randomized_hunter_agent_function, monster_agent_function_simple, n=10, max_steps=100, visualize=False) for _ in range(100)] \n",
    "print(steps)\n",
    "\n",
    "print (f\"Hunter failed {np.sum(np.isnan(steps))} times.\")\n",
    "print (f\"Average steps to catch the monster over successful runs: {round(np.nanmean(steps), 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This in not a very good agent. You need to implement a better agent function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Agent Implementation\n",
    "\n",
    "Write a new hunter agent function that chases the monster. Copy the simple randomized hunter function from above and modify it using rules based on the monster and hunter location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here goes your agent implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Experiments\n",
    "\n",
    "Copy the simulation code from above and run experiments with your agent. \n",
    "Experiment with larger arenas of at least size $30 \\times 30$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your experimentation code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Conclusion\n",
    "\n",
    "Discuss what your final strategy is and how the arena size affects your hunter agent's performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Your discussion goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The monster is also an agent. Describe how the monster's agent function could be changed so it gets better at avoiding the hunter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Your discussion goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Work (Optional)\n",
    "\n",
    "Here are some ideas:\n",
    "\n",
    "* Implement a better monster agent function and perform experiments\n",
    "* Change the environment so multiple hunters can hunt the monster.\n",
    "* Give the hunter a new action that shoots an arrow in a specific direction. The arrow can go a maximum of 5 squares. \n",
    "  If the hunter hits the monster, then it wins.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
